{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "print('Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "ds = load_dataset(\"nvidia/HelpSteer\")\n",
    "\n",
    "train = pd.DataFrame(ds['train']) # len(train) = 35331 (95%)\n",
    "val = pd.DataFrame(ds['validation'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver Version: b'535.161.07'\n"
     ]
    }
   ],
   "source": [
    "from pynvml import *\n",
    "nvmlInit()\n",
    "print(f\"Driver Version: {nvmlSystemGetDriverVersion()}\")\n",
    "deviceCount = nvmlDeviceGetCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 : b'NVIDIA GeForce RTX 4090'\n"
     ]
    }
   ],
   "source": [
    "for i in range(deviceCount):\n",
    "     handle = nvmlDeviceGetHandleByIndex(i)\n",
    "     print(f\"Device {i} : {nvmlDeviceGetName(handle)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total memory: 25757220864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "info = nvmlDeviceGetMemoryInfo(handle)\n",
    "print(f\"Total memory: {info.total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-13 17:50:14--  https://raw.githubusercontent.com/scottclowe/cpu-gpu-utilisation-logging-python/master/log_gpu_cpu_stats.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12519 (12K) [text/plain]\n",
      "Saving to: ‘log_gpu_cpu_stats.py’\n",
      "\n",
      "log_gpu_cpu_stats.p 100%[===================>]  12.23K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-13 17:50:14 (180 MB/s) - ‘log_gpu_cpu_stats.py’ saved [12519/12519]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/scottclowe/cpu-gpu-utilisation-logging-python/master/log_gpu_cpu_stats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started logging compute utilisation\n"
     ]
    }
   ],
   "source": [
    "# Start the logger running in a background process. It will keep running until you tell it to stop.\n",
    "# We will save the CPU and GPU utilisation stats to a CSV file every 0.2 seconds.\n",
    "import subprocess\n",
    "!rm -f log_compute.csv\n",
    "logger_fname = 'log_compute.csv'\n",
    "logger_pid = subprocess.Popen(\n",
    "    ['python3', 'log_gpu_cpu_stats.py',\n",
    "     logger_fname,\n",
    "     '--loop',  '0.2',  # Interval between measurements, in seconds (optional, default=1)\n",
    "    ])\n",
    "print('Started logging compute utilisation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated the compute utilisation logger background process\n"
     ]
    }
   ],
   "source": [
    "logger_pid.terminate()\n",
    "print('Terminated the compute utilisation logger background process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-03-13 18:40:08--  https://raw.githubusercontent.com/scottclowe/cpu-gpu-utilisation-logging-python/master/log_gpu_cpu_stats.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12519 (12K) [text/plain]\n",
      "Saving to: ‘log_gpu_cpu_stats.py’\n",
      "\n",
      "log_gpu_cpu_stats.p 100%[===================>]  12.23K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-03-13 18:40:08 (246 MB/s) - ‘log_gpu_cpu_stats.py’ saved [12519/12519]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/scottclowe/cpu-gpu-utilisation-logging-python/master/log_gpu_cpu_stats.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n",
      "CPU times: user 27 µs, sys: 0 ns, total: 27 µs\n",
      "Wall time: 24.6 µs\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"nvidia/HelpSteer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"nvidia/HelpSteer\")\n",
    "\n",
    "train = ds['train'] # len(train) = 35331 (95%)\n",
    "val = ds['validation']     # len(val) = 1789 (5%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the three most important things to consider when deciding what technology to use to build an assist device to help an elderly person with basic needs?\n"
     ]
    }
   ],
   "source": [
    "for i in train:\n",
    "    print(i['prompt'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "x=[]\n",
    "start=time.time()\n",
    "for i in train:\n",
    "    x.append(i['prompt'])\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompts']=x\n",
    "df.to_csv('./all-prompts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df.iloc[12]['prompts']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sam/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        What are the three most important things to co...\n",
       "1        What are the three most important things to co...\n",
       "2        What are the three most important things to co...\n",
       "3        What are the three most important things to co...\n",
       "4        Background:\\n<start of reference>\\nFamily doct...\n",
       "                               ...                        \n",
       "35326    Consider this reference information delimited ...\n",
       "35327    according to the following reference text deli...\n",
       "35328    according to the following reference text deli...\n",
       "35329    according to the following reference text deli...\n",
       "35330    according to the following reference text deli...\n",
       "Name: prompts, Length: 35331, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prompts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_len']=df.apply(lambda row: len(nltk.word_tokenize(row['prompts'])),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_len\n",
       "15      482\n",
       "16      479\n",
       "14      464\n",
       "13      452\n",
       "17      372\n",
       "       ... \n",
       "1046      1\n",
       "356       1\n",
       "1193      1\n",
       "1360      1\n",
       "1400      1\n",
       "Name: count, Length: 1244, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['token_len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          (4.301, 39.98]\n",
       "1          (4.301, 39.98]\n",
       "2          (4.301, 39.98]\n",
       "3          (4.301, 39.98]\n",
       "4         (515.7, 549.68]\n",
       "               ...       \n",
       "35326    (549.68, 583.66]\n",
       "35327    (889.48, 923.46]\n",
       "35328    (889.48, 923.46]\n",
       "35329    (889.48, 923.46]\n",
       "35330    (889.48, 923.46]\n",
       "Name: token_len, Length: 35331, dtype: category\n",
       "Categories (50, interval[float64, right]): [(4.301, 39.98] < (39.98, 73.96] < (73.96, 107.94] < (107.94, 141.92] ... (1569.08, 1603.06] < (1603.06, 1637.04] < (1637.04, 1671.02] < (1671.02, 1705.0]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_freq=pd.cut(df['token_len'],bins=50)\n",
    "group_freq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
